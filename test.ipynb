{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is start, Scene is UP_RIGHT, Configuration is 1_2\n",
      "\n",
      "Re-initialized location to Start location\n",
      "True motion direction is null, motion coherence is 0.0\n",
      "\n",
      "Qs:[array([1.e+00, 1.e-16, 1.e-16, 1.e-16, 1.e-16])\n",
      " array([1.00000000e+00, 1.00000147e-32])]\n",
      "G: [-2.30308522 -2.30208522]\n",
      "q_pi: [0.49600009 0.50399991]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m     obs_h \u001b[38;5;241m=\u001b[39m label_to_indices(mappings_high, what_obs_h, where_obs_h, dimensions_high)\n\u001b[1;32m    129\u001b[0m     use_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m qs_high \u001b[38;5;241m=\u001b[39m \u001b[43magent_high\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistr_obs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_dist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m scene_beliefs_high[t_h,:] \u001b[38;5;241m=\u001b[39m qs_high[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    133\u001b[0m agent_high\u001b[38;5;241m.\u001b[39minfer_policies()\n",
      "File \u001b[0;32m~/graph_websearch_agent/pymdp/agent.py:512\u001b[0m, in \u001b[0;36mAgent.infer_states\u001b[0;34m(self, observation, distr_obs)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m         empirical_prior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD\n\u001b[0;32m--> 512\u001b[0m     qs \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_posterior_states_factorized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmb_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mempirical_prior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_params\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMMP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_obs\u001b[38;5;241m.\u001b[39mappend(observation)\n",
      "File \u001b[0;32m~/graph_websearch_agent/pymdp/inference.py:389\u001b[0m, in \u001b[0;36mupdate_posterior_states_factorized\u001b[0;34m(A, obs, num_obs, num_states, mb_dict, prior, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m valid_mb_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA_factor_list\u001b[39m\u001b[38;5;124m'\u001b[39m: [mb_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA_factor_list\u001b[39m\u001b[38;5;124m'\u001b[39m][m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_modalities) \u001b[38;5;28;01mif\u001b[39;00m obs[m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA_modality_list\u001b[39m\u001b[38;5;124m'\u001b[39m: [[old_to_new_idx[m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m modlist \u001b[38;5;28;01mif\u001b[39;00m obs[m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;28;01mfor\u001b[39;00m modlist \u001b[38;5;129;01min\u001b[39;00m mb_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA_modality_list\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    386\u001b[0m }\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Process valid observations\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m processed_obs \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_num_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prior \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     prior \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_obj_array(prior)\n",
      "File \u001b[0;32m~/graph_websearch_agent/pymdp/utils.py:344\u001b[0m, in \u001b[0;36mprocess_observation\u001b[0;34m(obs, num_modalities, num_observations)\u001b[0m\n\u001b[1;32m    342\u001b[0m     obs_arr_arr \u001b[38;5;241m=\u001b[39m obj_array(num_modalities)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_modalities):\n\u001b[0;32m--> 344\u001b[0m         obs_arr_arr[m] \u001b[38;5;241m=\u001b[39m \u001b[43monehot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_observations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     obs \u001b[38;5;241m=\u001b[39m obs_arr_arr\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "File \u001b[0;32m~/graph_websearch_agent/pymdp/utils.py:108\u001b[0m, in \u001b[0;36monehot\u001b[0;34m(value, num_values)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21monehot\u001b[39m(value, num_values):\n\u001b[1;32m    107\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_values)\n\u001b[0;32m--> 108\u001b[0m     \u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "from pymdp.agent import Agent\n",
    "from pymdp import utils, maths, control\n",
    "from pymdp.envs import SceneConstruction, RandomDotMotion, initialize_scene_construction_GM, initialize_RDM_GM\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "#### Initialize the parameters of the high-level POMDP and create a high level agent using the generative model parameters\n",
    "\n",
    "T_high = 6\n",
    "reward = 2.0\n",
    "punishment = -4.0\n",
    "urgency = -4.0\n",
    "params_high, mappings_high, dimensions_high = initialize_scene_construction_GM(T=T_high, reward=reward, punishment=punishment, urgency=urgency)\n",
    "agent_high = Agent(**params_high)\n",
    "\n",
    "#### Initialize the high-level environment\n",
    "\n",
    "scene_name = \"UP_RIGHT\" # options are \"UP_RIGHT\", \"RIGHT_DOWN\", \"DOWN_LEFT\", and \"LEFT_UP\"\n",
    "config = \"1_2\"          # options are all combinations of (1,2,3,4) in pairs of twos in all orders, but no repeats (e.g. \"1_2\", \"2_1\", \"1_3\", \"3_1\", \"1_4\", ...)\n",
    "env_high_level = SceneConstruction(scene_name = scene_name, config = config)\n",
    "what_obs_h, where_obs_h = env_high_level.reset()\n",
    "\n",
    "#### Initialize the parameters of the low-level POMDP and create a low-level agent using the generative model parameters\n",
    "\n",
    "T_low = 16\n",
    "p_low = 1.0\n",
    "urgency = 0.001\n",
    "params_low, mappings_low, dimensions_low = initialize_RDM_GM(T=T_low, A_precis=p_low, break_reward=urgency)\n",
    "agent_low = Agent(**params_low)\n",
    "\n",
    "#### initialize the low-level environment\n",
    "\n",
    "true_direction = \"null\"\n",
    "dot_precision = 1.0\n",
    "env_low_level = RandomDotMotion(precision=dot_precision, dot_direction=true_direction)\n",
    "what_obs_l, where_obs_l = env_low_level.reset()\n",
    "\n",
    "#### Write some \"linking\" functions that link inputs and outputs from different levels to eachother\n",
    "\n",
    "def get_prior_from_above(beliefs_high):\n",
    "\n",
    "    expected_obs = maths.spm_dot(params_high['A'][0], beliefs_high) # map `q_states` through the likelihood mapping to make a prior over the hidden states of the lower-level agent\n",
    "    empirical_prior = utils.obj_array_zeros(dimensions_low['num_states']) # make an empirical prior over hidden states at the low-level\n",
    "    empirical_prior[0] = expected_obs[:5]\n",
    "    empirical_prior[1] = utils.onehot(0, dimensions_low['num_states'][1])\n",
    "\n",
    "    return empirical_prior\n",
    "\n",
    "def get_obs_from_below(beliefs_low, where_obs_h):\n",
    "\n",
    "    obs_h = utils.obj_array_zeros(dimensions_high['num_obs'])\n",
    "    obs_h[0][:5] = beliefs_low[0]\n",
    "\n",
    "    where_obs_h_idx = mappings_high['where_obs_names'].index(where_obs_h)\n",
    "    obs_h[1] = utils.onehot(where_obs_h_idx, dimensions_high['num_obs'][1])\n",
    "\n",
    "    return obs_h\n",
    "\n",
    "#### Write some functions that map between semantic (e.g. \"UP\", \"2\", \"choose_UP_RIGHT\") and discrete ordinal (0, 1, 2, ..) labels for observations\n",
    "\n",
    "# For debugging - add print statements to see what's happening\n",
    "def label_to_indices(mappings, what_obs, where_obs, dimensions):\n",
    "    \"\"\" Maps from two strings `what_obs` and `where_obs` to their corresponding observation index \"\"\"\n",
    "    # Convert labels to indices \n",
    "    what_idx = int(mappings['what_obs_names'].index(what_obs))\n",
    "    where_idx = int(mappings['where_obs_names'].index(where_obs))\n",
    "\n",
    "    # If this is for the low level (checking by dimension), return tuple of indices\n",
    "    if len(mappings['what_obs_names']) == 5:  # Low level has 5 what_obs states\n",
    "        return (what_idx, where_idx)\n",
    "    \n",
    "    # Otherwise this is high level, return object array with one-hot vectors\n",
    "    obs_h = utils.obj_array_zeros(dimensions['num_obs']) \n",
    "    obs_h[0] = utils.onehot(what_idx, len(mappings['what_obs_names']))\n",
    "    obs_h[1] = utils.onehot(where_idx, len(mappings['where_obs_names']))\n",
    "    return obs_h\n",
    "\n",
    "def indices_to_label(mappings, what_obs_idx, where_obs_idx):\n",
    "    \"\"\" Maps from two indices `what_obs_idx` and `where_obs_idx` to their corresponding observation label \"\"\"\n",
    "    what_obs = mappings['what_obs_names'][what_obs_idx]\n",
    "    where_obs = mappings['where_obs_names'][where_obs_idx]\n",
    "    return what_obs, where_obs\n",
    "\n",
    "#### Set up initial high and low level observations\n",
    "\n",
    "obs_h = label_to_indices(mappings_high, what_obs_h, where_obs_h, dimensions_high)\n",
    "qs_high = agent_high.D\n",
    "\n",
    "#### Create some variables to store the history of choices\n",
    "\n",
    "scene_beliefs_high = np.zeros((T_high, dimensions_high['num_states'][0]))\n",
    "direction_beliefs_low = np.zeros((T_high, T_low, dimensions_low['num_states'][0]))\n",
    "search_choices_high = []\n",
    "sampling_prob_low = np.zeros((T_high, T_low, 2))\n",
    "\n",
    "#### Hierarchical active inference loop\n",
    "\n",
    "for t_h in range(T_high):\n",
    "\n",
    "    empirical_prior = get_prior_from_above(beliefs_high=qs_high)\n",
    "    agent_low.reset(init_qs=empirical_prior)\n",
    "\n",
    "    # reset the low-level process\n",
    "    sampling_action = 'sample'\n",
    "    t_s = 0\n",
    "    if where_obs_h in ['1','2','3','4']:\n",
    "        what_obs_l, where_obs_l = env_low_level.reset(dot_direction = what_obs_h, sampling_state = sampling_action)\n",
    "    else:\n",
    "        what_obs_l, where_obs_l = env_low_level.reset(dot_direction = 'null', sampling_state = sampling_action)\n",
    "\n",
    "    obs_l = label_to_indices(mappings_low, what_obs_l, where_obs_l, dimensions_low)\n",
    "\n",
    "    while (t_s < T_low) and (sampling_action == 'sample'):\n",
    "        qs_low = agent_low.infer_states(obs_l)\n",
    "        direction_beliefs_low[t_h, t_s, :] = qs_low[0].copy()\n",
    "        q_pi, _ = agent_low.infer_policies()\n",
    "        sampling_prob_low[t_h, t_s, :] = q_pi.copy()\n",
    "        chosen_action_id = agent_low.sample_action()\n",
    "        sampling_action = mappings_low['action_names'][int(chosen_action_id[1])]\n",
    "        what_obs_l, where_obs_l = env_low_level.step(sampling_action)\n",
    "        obs_l = label_to_indices(mappings_low, what_obs_l, where_obs_l, dimensions_low)\n",
    "        t_s += 1 \n",
    "    \n",
    "    if where_obs_h in ['1','2','3','4']:\n",
    "        obs_h = get_obs_from_below(beliefs_low=qs_low, where_obs_h=where_obs_h)\n",
    "        use_dist = True\n",
    "    else:\n",
    "        obs_h = label_to_indices(mappings_high, what_obs_h, where_obs_h, dimensions_high)\n",
    "        use_dist = False\n",
    "\n",
    "    qs_high = agent_high.infer_states(obs_h, distr_obs = use_dist)\n",
    "    scene_beliefs_high[t_h,:] = qs_high[0].copy()\n",
    "    agent_high.infer_policies()\n",
    "    chosen_action_id = agent_high.sample_action()\n",
    "    movement_id = int(chosen_action_id[1])\n",
    "    search_action = mappings_high['action_names'][movement_id]\n",
    "    what_obs_h, where_obs_h = env_high_level.step(search_action)\n",
    "\n",
    "    # get expected states over the next location, given the action just taken\n",
    "    qs_high = control.get_expected_states(qs_high, agent_high.B, chosen_action_id.reshape(1,-1))[0]\n",
    "\n",
    "    # append last saccade action to history of choices\n",
    "    search_choices_high.append(search_action)\n",
    "      \n",
    "\n",
    "#### Now do some plotting of the hierarchical agent's inference over time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "def plot_beliefs_hierarchical(beliefs_low, beliefs_high, t_high_to_show):\n",
    "  fig = plt.figure(tight_layout=True,figsize=(10,12))\n",
    "\n",
    "  num_sub_t_step = len(t_high_to_show)\n",
    "  gs = gridspec.GridSpec(num_sub_t_step, num_sub_t_step)\n",
    "\n",
    "  T_high = beliefs_high.shape[0]\n",
    "  beliefs_high = beliefs_high.reshape(beliefs_high.shape[0], 4, 12).sum(2) # average across configurations\n",
    "  ax_top = fig.add_subplot(gs[0, :])\n",
    "  imdata = ax_top.imshow(beliefs_high.T, clim = (0.0, 1.0))\n",
    "  ax_top.set_xticks(np.arange(T_high))\n",
    "  ax_top.set_yticks(np.arange(4))\n",
    "  ax_top.set_yticklabels(labels = mappings_high['scene_names'], rotation=45)\n",
    "  fig.colorbar(imdata, ax=ax_top)\n",
    "  \n",
    "  for t_h in t_high_to_show:\n",
    "    ax_top.add_patch(Rectangle((t_h-0.5, -0.5), 1, 5, edgecolor='red', fill=False, lw=3))\n",
    "    ax_top.text(t_h-0.25, 2.0, f't = {t_h}', fontsize=12.5, color = 'white', rotation = 30)\n",
    "\n",
    "  for (i,t_h) in enumerate(t_high_to_show):\n",
    "    ax = fig.add_subplot(gs[1, i])\n",
    "\n",
    "    ax.plot(beliefs_low[t_h,:,1], label = '$P(Up)$')\n",
    "    ax.plot(beliefs_low[t_h,:,2], label = '$P(Right)$')\n",
    "    ax.plot(beliefs_low[t_h,:,3], label = '$P(Down)$')\n",
    "    ax.plot(beliefs_low[t_h,:,4], label = '$P(Left)$')\n",
    "    ax.set_xlim(0, beliefs_low.shape[1])\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_ylabel('Inferred probability of motion')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_title('$T_h = $' + f'{t_h}')\n",
    "\n",
    "plot_beliefs_hierarchical(direction_beliefs_low, scene_beliefs_high, [0, 1, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
